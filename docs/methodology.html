<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Methodology | BCI Classifier</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&family=Roboto+Mono:wght@300;400;500&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="css/neuralink.css">
</head>

<body>
    <div class="overlay-scanlines"></div>
    <div class="app-container">

        <nav class="main-nav">
            <a href="index.html" class="nav-link">Home</a>
            <a href="ml-demo.html" class="nav-link">Interface</a>
            <a href="methodology.html" class="nav-link active">Methodology</a>
            <a href="results.html" class="nav-link">Results</a>
            <a href="documentation.html" class="nav-link">Docs</a>
        </nav>

        <main class="content-container">
            <h1>Methodology</h1>
            <p>Our four-phase approach to predicting BCI performance from early trial data.</p>

            <h2>Phase 1: Ground Truth Label Generation</h2>
            <p>We establish baseline performance metrics for each subject using standard MetaBCI decoders. This involves
                processing the PhysionetMI dataset (109 subjects) to generate valid accuracy labels.</p>

            <h3>Dataset & Decoder</h3>
            <ul>
                <li><strong>Dataset:</strong> PhysionetMI (Motor Imagery, 64 channels)</li>
                <li><strong>Decoder:</strong> CSP (4 components) + LDA</li>
                <li><strong>Filtering:</strong> 7-30 Hz Bandpass</li>
                <li><strong>Validation:</strong> 5-fold Stratified Cross-Validation (Within-Subject)</li>
            </ul>

            <h2>Phase 2: Feature Extraction</h2>
            <p>We extract neurophysiological markers from the <strong>first 15 trials</strong> of each subject. These
                "early features" are hypothetical predictors of final BCI literacy.</p>

            <div class="card-grid">
                <div class="nav-card">
                    <span class="card-title">1. Spectral Features (12)</span>
                    <span class="card-desc">
                        <ul style="padding-left: 15px; margin-top: 5px; font-size: 0.8em; color: #888;">
                            <li><strong>Band Power:</strong> Mu (8-13Hz) & Beta (13-30Hz) at C3, Cz, C4 (6 features)
                            </li>
                            <li><strong>ERD/ERS:</strong> Event-Related Desynchronization relative to baseline (6
                                features)</li>
                        </ul>
                    </span>
                </div>
                <div class="nav-card">
                    <span class="card-title">2. Spatial Features (4)</span>
                    <span class="card-desc">
                        <ul style="padding-left: 15px; margin-top: 5px; font-size: 0.8em; color: #888;">
                            <li>CSP Eigenvalue Ratio</li>
                            <li>CSP Feature Mean & Std Dev</li>
                            <li>Class Separability Index</li>
                        </ul>
                    </span>
                </div>
                <div class="nav-card">
                    <span class="card-title">3. Temporal Stability (7)</span>
                    <span class="card-desc">
                        <ul style="padding-left: 15px; margin-top: 5px; font-size: 0.8em; color: #888;">
                            <li>Signal-to-Noise Ratio (Mean, Max, Std)</li>
                            <li>Trial Variability (CV Mean, CV Std)</li>
                            <li>Inter-trial Correlation</li>
                            <li>P300 Stability Score</li>
                        </ul>
                    </span>
                </div>
            </div>
            <p style="text-align: center; font-size: 0.8rem; color: #666; margin-top: 10px;">Total Feature Vector
                Dimension: <strong>R²³</strong></p>

            <h2>Phase 3: Performance Prediction</h2>
            <p>We train regression models to map Early Features (X) to Final Accuracy (Y).</p>
            <pre><code>Model: Random Forest Regressor
Input: 23 Features (from 15 trials)
Target: 5-fold CV Accuracy (from all trials)
Performance: R² = 0.24, Pearson r = 0.52</code></pre>

            <p>We compared multiple algorithms (XGBoost, SVM, Ridge) and found Random Forest to be the most robust to
                noise and varying subject baselines.</p>

            <h2>Limitations & Accuracy Context</h2>
            <p>Our current predictions often hover around 55-65%. It is important to contextualize this:</p>
            <ul>
                <li><strong>Zero-Calibration Challenge:</strong> This model assumes <em>no prior training</em> for the
                    subject. In BCI, achieving >60% accuracy without user feedback training (Neurofeedback) is
                    statistically significant for a 2-class problem.</li>
                <li><strong>Subject Variability:</strong> The "BCI Illiteracy" phenomenon affects ~15-20% of the
                    population, who naturally do not exhibit strong ERD signals. Our model correctly identifies these
                    users as "Low Accuracy".</li>
                <li><strong>Short-Time Window:</strong> We are predicting long-term performance based on only the first
                    45 seconds of data (15 trials).</li>
            </ul>

            <h2>System Architecture: Simulation vs. Real-time</h2>
            <p>The current demonstration utilizes a <strong>Hardware-in-the-Loop (HIL) Simulation</strong> architecture.
            </p>
            <ul>
                <li><strong>Signal Source (Simulator):</strong> Instead of a live headset, we stream pre-recorded,
                    validated EEG data from the PhysioNet database. This acts as a "Digital Twin" of a patient.</li>
                <li><strong>Processing Pipeline (Real-time):</strong> The feature extraction, signal processing, and ML
                    decoding happen in real-time (on the fly) as the data is streamed.</li>
                <li><strong>Justification:</strong> This allows us to validate the end-to-end latency and visualization
                    pipeline deterministically before deployment with human subjects.</li>
            </ul>

            <h2>Software Stack</h2>
            <ul>
                <li>Python 3.9+</li>
                <li>MNE-Python (EEG Processing)</li>
                <li>MetaBCI (Decoding Pipelines)</li>
                <li>scikit-learn (Machine Learning)</li>
                <li>Flask (API)</li>
            </ul>
        </main>
    </div>
</body>

</html>